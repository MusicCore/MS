server.port=80
##开发环境配置文件
#spring.profiles.active=dev
#开启驼峰映射
#mybatis.configuration.map-underscore-to-camel-case=true
#DataBase
#startspring.datasource.url=jdbc:mysql://localhost:3306/music_score?useUnicode=true&characterEncoding=UTF-8&serverTimezone=GMT%2B8
spring.datasource.url=jdbc:mysql://167.179.96.195:3306/music_score?useUnicode=true&characterEncoding=UTF-8&serverTimezone=GMT%2B8
spring.datasource.username=music_score
spring.datasource.password=123456
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
#DataBase end
##################    连接池配置    ################
#连接池建立时创建的初始化连接数
spring.datasource.druid.initial-size=5
#连接池中最大的活跃连接数
spring.datasource.druid.max-active=20
#连接池中最小的活跃连接数
spring.datasource.druid.min-idle=5
# 配置获取连接等待超时的时间
spring.datasource.druid.max-wait=60000
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.druid.pool-prepared-statements=true
spring.datasource.druid.max-pool-prepared-statement-per-connection-size=20
#spring.datasource.druid.max-open-prepared-statements= #和上面的等价
spring.datasource.druid.validation-query=SELECT 1 FROM DUAL
spring.datasource.druid.validation-query-timeout=30000
#是否在获得连接后检测其可用性
spring.datasource.druid.test-on-borrow=false
#是否在连接放回连接池后检测其可用性
spring.datasource.druid.test-on-return=false
#是否在连接空闲一段时间后检测其可用性
spring.datasource.druid.test-while-idle=true
#DataBase end
# WebStatFilter配置，说明请参考Druid Wiki，配置_配置WebStatFilter
#是否启用StatFilter默认值true
#spring.datasource.druid.web-stat-filter.enabled=true
#spring.datasource.druid.web-stat-filter.url-pattern=/*
#spring.datasource.druid.web-stat-filter.exclusions=*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*
#spring.datasource.druid.web-stat-filter.session-stat-enable=false
#spring.datasource.druid.web-stat-filter.session-stat-max-count=1000
#spring.datasource.druid.web-stat-filter.principal-session-name=admin
#spring.datasource.druid.web-stat-filter.principal-cookie-name=admin
#spring.datasource.druid.web-stat-filter.profile-enable=true
# StatViewServlet配置
#展示Druid的统计信息,StatViewServlet的用途包括：1.提供监控信息展示的html页面2.提供监控信息的JSON API
#是否启用StatViewServlet默认值true
spring.datasource.druid.stat-view-servlet.enabled=true
#根据配置中的url-pattern来访问内置监控页面，如果是上面的配置，内置监控页面的首页是/druid/index.html例如：
#http://110.76.43.235:9000/druid/index.html
spring.datasource.druid.stat-view-servlet.url-pattern=/druid/*
#允许清空统计数据
spring.datasource.druid.stat-view-servlet.reset-enable=true
spring.datasource.druid.stat-view-servlet.login-username=admin
spring.datasource.druid.stat-view-servlet.login-password=123456
#StatViewSerlvet展示出来的监控信息比较敏感，是系统运行的内部情况，如果你需要做访问控制，可以配置allow和deny这两个参数
#deny优先于allow，如果在deny列表中，就算在allow列表中，也会被拒绝。如果allow没有配置或者为空，则允许所有访问
#配置的格式
#<IP>
#或者<IP>/<SUB_NET_MASK_size>其中128.242.127.1/24
#24表示，前面24位是子网掩码，比对的时候，前面24位相同就匹配,不支持IPV6。
spring.datasource.druid.stat-view-servlet.allow=
spring.datasource.druid.stat-view-servlet.deny=128.242.127.1/24,128.242.128.1

# mongodb start
#spring.data.mongodb.uri=mongodb://localhost:27017/springboot-db

#mybatis start
mybatis.config-location=classpath:/mybatis-config.xml
#mybatis end

#配置外部静态资源
#spring.resources.static-locations=C:/Users/98070/Desktop/test

#thymeleaf start
spring.thymeleaf.prefix=classpath:/templates/
spring.thymeleaf.mode=HTML5
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.servlet.content-type=text/html
#开发时关闭缓存,不然没法看到实时页面
spring.thymeleaf.cache=false
spring.thymeleaf.suffix=.html
#thymeleaf end

#uploadFileSize start
#spring.servlet.multipart.max-file-size=10Mb
#spring.servlet.multipart.max-request-size=100Mb
#uploadFileSize end

##集成mybatis
mybatis.mapper-locations=classpath:/mapper/*Mapper.xml
spring.mail.host=smtp.exmail.qq.com
spring.mail.username=test@qq.com
spring.mail.password=test
spring.mail.from=test@qq.com

##redis
#redis.host=127.0.0.1
#redis.port=6379
#redis.timeout=10
#redis.poolMaxTotal=1000
#redis.poolMaxIdle=500
#redis.poolMaxWait=500


#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=localhost:9092

#=============== provider  =======================

spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-consumer-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100
#设置上传文件大小为无限制
spring.servlet.multipart.maxFileSize=-1
spring.servlet.multipart.maxRequestSize=-1

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#热部署
spring.devtools.restart.enabled=true
spring.freemarker.cache=false

